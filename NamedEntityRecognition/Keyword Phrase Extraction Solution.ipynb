{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Phrase Extraction\n",
    "## This notebook outlines the concepts involved in extracting keyword phrases in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: **Identify keywords in a piece of text**\n",
    "\n",
    "Identify **words that are very important** in a piece of text\n",
    "\n",
    "### Possible Solutions:\n",
    "- TF-IDF (already seen)\n",
    "- Noun Chunks\n",
    "- - Specialized Keyword Extraction algorithms\n",
    "    - TextRank\n",
    "    - SGRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textacy is an excellent library that uses several information extraction functions, many of them based on regular expression patterns and heuristics to address extracting specific expressions such as acronyms and quotations. Apart from these, one can also extract matching custom regular expressions including POS tag patterns, or look for statements involving an entity, subject-verb-object tuples etc. \n",
    "\n",
    "We will use Textacy to extract keywords from documents\n",
    "\n",
    "Documentaion: https://textacy.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textacy==0.9.1\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prite\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "from textacy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a spacy model, which will be used for all further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = textacy.load_spacy_lang(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a sample text to find keywords\n",
    "- kpe_sample_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = open('kpe_sample_text.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the text into a spacy document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = textacy.make_spacy_doc(mytext, lang=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Common NLP Tasks, following, list, some, most commonly researched tasks, natural language processing, Some, tasks, direct real-world applications, others, subtasks, that, larger tasks, natural language processing tasks, they, categories, convenience, coarse division, Text and speech processing\n",
      "Optical character recognition, OCR, image, printed text, corresponding text, Speech recognition, sound clip, person, people, textual representation, speech, This, opposite, text, extremely difficult problems, natural speech, pauses, successive words, speech segmentation, necessary subtask, speech recognition, most spoken languages, sounds, successive letters, process, coarticulation, conversion, analog signal, discrete characters, very difficult process, words, same language, people, different accents, speech recognition software, wide variety, input, terms, its textual equivalent, Speech segmentation, sound clip, person, people, it, words, subtask, speech recognition, it, speech, text, units, spoken representation, Text, -speech, visually impaired.[18, Word segmentation, Tokenization, chunk, continuous text, separate words, language, English, this, words, spaces, written languages, Chinese, Japanese, Thai, word boundaries, a fashion, languages text segmentation, significant task, knowledge, vocabulary, morphology, words, language, process, cases, bag, words, (BOW) creation, data mining, Morphological analysis\n",
      "Lemmatization\n",
      "The task, inflectional endings, base dictionary form, word, which, lemma, Lemmatization, technique, words, their normalized form, case, transformation, dictionary, words, their actual form.[19, Morphological segmentation\n",
      "Separate words, individual morphemes, class, morphemes, difficulty, task, complexity, morphology, (i.e., the structure, words, language, English, fairly simple morphology, especially inflectional morphology, it, task, possible forms, word, separate words, languages, Meitei,[20, highly agglutinated Indian language, an approach, dictionary entry, thousands, possible word forms, speech, sentence, part, speech, POS, word, Many words, especially common ones, multiple parts, speech, example, book, noun, (\"the book, table, verb, flight, \"set, noun, verb, any, at least five different parts, speech, process, inflected, words, base form, root, \"closing, similar results, lemmatization, grounds, rules, not a dictionary, Syntactic analysis\n",
      "Grammar induction[21, formal grammar, that, language's syntax, Sentence breaking, sentence boundary disambiguation, chunk, text, sentence boundaries, Sentence boundaries, periods, other punctuation marks, same characters, other purposes, abbreviations, Parsing, parse tree, grammatical analysis, given sentence, grammar, natural languages, ambiguous and typical sentences, multiple possible analyses, typical sentence, thousands, potential parses, which, human, two primary types, dependency parsing, Dependency parsing, relationships, words, sentence, things, primary objects, predicates, parse tree, probabilistic context-free grammar, PCFG, stochastic grammar, Lexical semantics, individual words, context, Lexical semantics, What, computational meaning, individual words, context, Distributional semantics, we, semantic representations, data, Named entity recognition, NER, stream, text, items, text map, proper names, people, places, what, type, such name, e.g. person, location, organization, capitalization, named entities, languages, English, information, type, named entity, case, example, first letter, sentence, named entities, several words, only some, which, many other languages, non-Western scripts, capitalization, even languages, capitalization, it, names, example, nouns, they, names, French, Spanish, names, that, adjectives, Sentiment analysis, also multimodal sentiment analysis, subjective information, set, documents, online reviews, \"polarity, specific objects, It, trends, public opinion, social media, marketing, Terminology extraction, goal, terminology extraction, relevant terms, given corpus, Word sense, Many words, more than one meaning, we, meaning, which, most sense, context, problem, we, list, words, associated word senses, dictionary, online resource, WordNet, Relational semantics, semantics, individual sentences, Relationship extraction, chunk, text, relationships, named entities, who, whom, Semantic Parsing, piece, text, typically a sentence, formal representation, its semantics, graph, AMR parsing, accordance, logical formalism, DRT parsing, challenge, aspects, several more elementary NLP tasks, semantics, (e.g., semantic role labelling, word sense disambiguation, full-fledged discourse analysis, e.g., discourse analysis, coreference, Natural Language Understanding, Semantic Role Labelling, also implicit semantic role, single sentence, semantic predicates, verbal frames, frame elements, semantic roles, Discourse, (semantics, individual sentences, Coreference resolution, sentence, larger chunk, text, which, (\"mentions, same objects, (\"entities, Anaphora resolution, specific example, task, pronouns, nouns, names, which, they, more general task, coreference resolution, so-called \"bridging relationships, referring expressions, example, sentence, He, John's house, front door, front door, referring expression, bridging relationship, fact, door, front door, John's house, other structure, that, Discourse analysis, rubric, several related tasks, One task, discourse parsing, discourse structure, connected text, i.e. the nature, discourse relationships, sentences, e.g. elaboration, explanation, contrast, possible task, speech, chunk, text, (e.g. yes-no question, content question, statement, assertion, single sentence, semantic predicates, verbal frames, their explicit semantic roles, current sentence, Semantic Role Labelling, semantic roles, that, current sentence, them, arguments, that, text, those, that, local text, closely related task, zero anaphora resolution, , the extension, coreference resolution, pro-drop languages, Textual entailment, two text fragments, other's negation, Topic segmentation, recognition, chunk, text, it, segments, each, which, topic, topic, segment, Higher-level NLP applications, Automatic summarization, text summarization, readable summary, chunk, text, summaries, text, known type, research papers, articles, financial section, newspaper, Book generation, Not an NLP task, extension, Natural Language Generation, other NLP tasks, creation, full-fledged books, first machine-generated book, rule-based system, 1984 (Racter, policeman's beard, -constructed).[23, first published work, neural network, 1 the Road, novel, sixty million words, Both these systems, elaborate but non-sensical (semantics-free) language models, first machine-generated science book, Beta Writer, Lithium-Ion Batteries, Cham).[24, Racter, 1 the Road, this, factual knowledge, text summarization, Dialogue management\n",
      "Computer systems, human, Document AI\n",
      "A Document AI platform, top, NLP technology, users, prior experience, artificial intelligence, machine learning, NLP, computer, specific data, they, different document types, NLP-powered Document AI, non-technical teams, information, documents, example, business analysts, accountants.[25, Grammatical error correction\n",
      "Grammatical error detection, correction, great band-width, problems, levels, linguistic analysis, phonology/orthography, morphology, syntax, semantics, pragmatics, Grammatical error correction, it, hundreds of millions, people, that, English, second language, It, number, shared tasks, orthography, morphology, syntax, certain aspects, semantics, development, powerful neural language models, GPT-2, this, largely solved problem, various commercial applications.[29, Machine translation, text, one human language, another, This, most difficult problems, member, class, problems, all, different types, knowledge, that, humans, grammar, semantics, real world, Natural language generation, NLG, information, computer databases, semantic intents, readable human language, NLU, chunks, text, more formal representations, first-order logic structures, that, computer programs, Natural language understanding, identification, multiple possible semantics, which, natural language expression, which, form, organized notations, natural language concepts, Introduction, creation, language metamodel, ontology, efficient however empirical solutions, explicit formalization, natural language semantics, confusions, implicit assumptions, closed-world assumption, CWA, open-world assumption, subjective Yes/No vs. objective True/False, construction, basis, semantics formalization.[30]\n",
      "Question, human-language question, its answer, Typical questions, specific right answer, What, capital, Canada, open-ended questions, What, meaning, life, Recent works, even more complex questions]\n"
     ]
    }
   ],
   "source": [
    "print([chunk for chunk in textacy.extract.noun_chunks(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language semantic', 0.018146838505547314),\n",
       " ('natural language processing task', 0.018060171377632987),\n",
       " ('language text segmentation', 0.017039167515137954),\n",
       " ('possible word form', 0.011931118622641946),\n",
       " ('multiple possible semantic', 0.011782065218284243)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.extract.keyterms.textrank(doc, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language semantic', 0.018146838505547314),\n",
       " ('natural language processing task', 0.018060171377632987),\n",
       " ('language text segmentation', 0.017039167515137954),\n",
       " ('possible word form', 0.011931118622641946),\n",
       " ('multiple possible semantic', 0.011782065218284243),\n",
       " ('natural language expression', 0.011774393399104688),\n",
       " ('natural language generation', 0.011688724696224265),\n",
       " ('readable human language', 0.011669293765417333),\n",
       " ('powerful neural language model', 0.011598017813175949),\n",
       " ('natural language understanding', 0.01139476710406764),\n",
       " ('language question', 0.011350302842731216),\n",
       " ('natural language concept', 0.011169986552497629),\n",
       " ('Implicit semantic Role labelling', 0.010617673020212303),\n",
       " ('semantic role labelling', 0.010558625103431842),\n",
       " ('explicit semantic role', 0.010363135996829321),\n",
       " ('word sense disambiguation', 0.00964158598757856),\n",
       " ('semantic representation', 0.009522574211103165),\n",
       " ('spoken language', 0.009435681059633324),\n",
       " ('indian language', 0.009205679489025174),\n",
       " ('possible task', 0.009195327192620516)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.extract.keyterms.textrank(doc, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords using TextRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language semantic',\n",
       " 'natural language processing task',\n",
       " 'language text segmentation',\n",
       " 'possible word form',\n",
       " 'multiple possible semantic',\n",
       " 'natural language expression',\n",
       " 'natural language generation',\n",
       " 'readable human language',\n",
       " 'powerful neural language model',\n",
       " 'natural language understanding']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kps for kps, weights in textacy.extract.keyterms.textrank(doc, normalize=\"lemma\", topn=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords using SGRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language',\n",
       " 'speech recognition',\n",
       " 'word',\n",
       " 'text',\n",
       " 'task',\n",
       " 'separate word',\n",
       " 'sentence',\n",
       " 'sentence boundary',\n",
       " 'semantic role',\n",
       " 'segmentation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kps for kps, weights in textacy.extract.keyterms.sgrank(doc, topn=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: **Overlapping key phrases**\n",
    "\n",
    "Solution: **aggregage_term_variants**\n",
    "- Choosing one of the grouped terms per item will give us a list of non-overlapping key phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'speech recognition'}, {'sentence boundary'}, {'natural language'}, {'separate word'}, {'semantic role'}, {'segmentation'}, {'sentence'}, {'task'}, {'word'}, {'text'}]\n"
     ]
    }
   ],
   "source": [
    "terms = set([term for term,weight in textacy.extract.keyterms.sgrank(doc)])\n",
    "print(textacy.extract.utils.aggregate_term_variants(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ml-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d016fd0a616a1955da71f9fc5f1f4df272bd829d9e8530f2d8b60e7deac3f13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
